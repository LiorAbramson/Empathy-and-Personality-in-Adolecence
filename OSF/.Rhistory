#dividing the 6 folds so two twins from the same family will always be in the same test fold
#gfold is the variable allocating family to a sepcific fold
unique_ifams <- unique(DImp1.1$ifam)
set.seed(32189)
unique_ifams <- sample(unique_ifams)
remainder<-length(unique_ifams)%%6
nfold <- (length(unique_ifams)-remainder)/6
gfold <- c(rep(1, times=nfold), rep(2, times=nfold), rep(3, times=nfold),
rep(4, times=nfold), rep(5, times=nfold), rep(6, times=nfold))
gfold <- c(gfold,1:remainder)
unique_ifams <- cbind(unique_ifams,gfold)
ifams<- as.data.frame(rbind(unique_ifams, unique_ifams))
colnames(ifams) <- c("ifam","gfold")
ifams$ID<- c(rep(1,times=nrow(unique_ifams)),rep(4,times=nrow(unique_ifams)))  # allocate ID for each twin (ID 1=older twin, ID 4= younger twin)
DImp1.1<- merge(DImp1.1,ifams, by=c("ifam","ID"), all.x = T, all.y = F)        #merge the gfold var with the data
#############################################################################################
######################### Ridge regression ##################################################
#############################################################################################
#create a vector of possible lambda values. These values will be examined in
#a nexted cross-validation procedure to find the optimal lambda that produces the lowest prediction error
# lambdas <- 10^seq(3, -2, by = -.1)
#ridge regression function
Ridge <- function (DImp,gfold,relvar) {
#find the best lambda-
#use glmnet default range search by lambda=NULL
#alpha=0 means we use Ridge regression (as opposed to lasso regression)
#nfolds=10 means that the nested cross-validation proceudre to find the optimal lambda is perdormed on 10 folds
set.seed(10000)
cv_fit <- cv.glmnet(x=as.matrix(DImp[DImp$gfold != gfold,relvar[2:45]]),
y=DImp[DImp$gfold != gfold,relvar[1]],
alpha=0, lambda=NULL,nfolds=10)
opt_lambda <- cv_fit$lambda.min          #find the optimal lambda which produces the lowest prediction error
opt_lambda_ind <- which(cv_fit$lambda==opt_lambda)   #find the optimal lambda index inside the vector
#what are the coefficients when the lambda is optimal?
opt_coef <- as.matrix(cv_fit$glmnet.fit$beta[,opt_lambda_ind])
#after finding the best lambda, train the entire train set with that lambda
fit <- glmnet(x=as.matrix(DImp[DImp$gfold != gfold,relvar[2:45]]),
y=DImp[DImp$gfold != gfold,relvar[1]],
alpha = 0, lambda = opt_lambda)
#now check the prediction on the test set
y_pred <- predict(fit, s=opt_lambda,
newx = as.matrix(DImp[DImp$gfold == gfold,relvar[2:45]]))
mse <- mean((DImp[DImp$gfold == gfold,relvar[1]]-y_pred)^2)     #squared difference between y and y predicted
mean_train <- mean(DImp[DImp$gfold != gfold,relvar[1]])         #mean y (empathy score)
assign ("fit",fit,envir = .GlobalEnv)                           #glmnet ridge regression results
assign ("opt_lambda",opt_lambda,envir = .GlobalEnv)             #optimal lambda value
assign ("opt_coef",opt_coef,envir = .GlobalEnv)                 #items' coefficients when the lambda is optimal
assign ("y_pred",y_pred,envir = .GlobalEnv)                     #y predicted for each participant
assign ("mse", mse,envir = .GlobalEnv)                          #mse for the test set
}
#scale all the BFI items so they all will mean=0 and SD=1
for (i in 2:45) {DImp1.1[,relvar_emotional[i]] <-
scale(DImp1.1[,relvar_emotional[i]], scale=T)}
#doing Ridge regression on the folds - emotional empathy
#fold 1
Ridge(DImp=DImp1.1,gfold=1,relvar=relvar_emotional)
fit_emo11_1 <- fit
opt_lambda_emo11_1 <- opt_lambda
opt_coef_emo11_1 <- opt_coef
y_pred_emo11_1 <- y_pred
mse_emo11_1 <- mse
Rholdout_emo11_1 <- Rholdout
#fold 2
Ridge(DImp=DImp1.1,gfold=2,relvar=relvar_emotional)
fit_emo11_2 <- fit
opt_lambda_emo11_2 <- opt_lambda
opt_coef_emo11_2 <- opt_coef
y_pred_emo11_2 <- y_pred
mse_emo11_2 <- mse
Rholdout_emo11_2 <- Rholdout
#fold 3
Ridge(DImp=DImp1.1,gfold=3,relvar=relvar_emotional)
fit_emo11_3 <- fit
opt_lambda_emo11_3 <- opt_lambda
opt_coef_emo11_3 <- opt_coef
y_pred_emo11_3 <- y_pred
mse_emo11_3 <- mse
Rholdout_emo11_3 <- Rholdout
#fold 4
Ridge(DImp=DImp1.1,gfold=4,relvar=relvar_emotional)
fit_emo11_4 <- fit
opt_lambda_emo11_4 <- opt_lambda
opt_coef_emo11_4 <- opt_coef
y_pred_emo11_4 <- y_pred
mse_emo11_4 <- mse
Rholdout_emo11_4 <- Rholdout
#fold 5
Ridge(DImp=DImp1.1,gfold=5,relvar=relvar_emotional)
fit_emo11_5 <- fit
opt_lambda_emo11_5 <- opt_lambda
opt_coef_emo11_5 <- opt_coef
y_pred_emo11_5 <- y_pred
mse_emo11_5 <- mse
Rholdout_emo11_5 <- Rholdout
#fold 6
Ridge(DImp=DImp1.1,gfold=6,relvar=relvar_emotional)
fit_emo11_6 <- fit
opt_lambda_emo11_6 <- opt_lambda
opt_coef_emo11_6 <- opt_coef
y_pred_emo11_6 <- y_pred
mse_emo11_6 <- mse
Rholdout_emo11_6 <- Rholdout
#computing the mean coefficients across the folds
opt_coef_emo11_matrix <- as.data.frame(cbind (opt_coef_emo11_1,
opt_coef_emo11_2,
opt_coef_emo11_3,
opt_coef_emo11_4,
opt_coef_emo11_5,
opt_coef_emo11_6))
opt_coef_emo11_matrix$aveCoef <- rowMeans(opt_coef_emo11_matrix)
#finding the mean correlation between the outcome and predicted value (y pred) across the folds
cor_emo11 <-1:6
#first do this for each test set
for (i in 1:6) {
cor_emo11[i] <- cor.test(DImp1.1$EMPQ_emotional[DImp1.1$gfold ==i],
eval(parse(text=paste0("y_pred_emo11_",i))))[4]}
cor_emo11 <- as.numeric(cor_emo11)
#now average across all the folds
avecor_emo11 <- mean(cor_emo11)
#computing the mean mse across the folds
mse_emo11 <-1:6
for (i in 1:6) { mse_emo11[i] <- eval(parse(text=paste0("mse_emo11_",i)))}
avemse_emo11 <- mean(mse_emo11)
# This script performs the ridge regression, predicting empathy from Big-Five nuanced items
# and creates the empathic personality profiles
#Preparations
rm(list = ls()) # clean the global environment
cat ("\014")    #clean the R console
#Packages
packages <- c('psych', 'Hmisc', 'glmnet')
lapply(packages, require, character.only = TRUE)
#Preparing the file
D <- read.csv("../OSF/data/Age11_EmpPer_anonymized.csv")
D <- D[D$isOut==0,]                      #take out children that should not be included (see supplementary method)
D <- subset(D, !is.na(D$EMPQ_emotional)) #take out children with no empathy measures
#############################################################################################
######################### Data Preprocessing ################################################
#############################################################################################
#1) Handling missing values
#first count how many missing values are in each var:
ind <- which(colnames(D)=="el_BFI1")
descD <- describe(D[,ind:(ind+43)])
missingBFI11 <- (nrow(D)-descD$n)/nrow(D)   #calculate percentage of missing values
round(max(missingBFI11),4)                  #check what is the maximum of missing values in one variable
#Imputations of missing values for the Big5 (pmm)
set.seed(12) #set the random vector to always be the same vector
Imp_B5 <- aregImpute (formula= ~el_BFI1+ el_BFI2+ el_BFI3+ el_BFI4+ el_BFI5+ el_BFI6+ el_BFI7+ el_BFI8+el_BFI9+ el_BFI10+
el_BFI11+ el_BFI12+ el_BFI13+ el_BFI14+ el_BFI15+ el_BFI16+ el_BFI17+ el_BFI18+el_BFI19+ el_BFI20+
el_BFI21+ el_BFI22+ el_BFI23+ el_BFI24+ el_BFI25+ el_BFI26+ el_BFI27+ el_BFI28+el_BFI29+ el_BFI30+
el_BFI31+ el_BFI32+ el_BFI33+ el_BFI34+ el_BFI35+ el_BFI36+ el_BFI37+ el_BFI38+el_BFI39+ el_BFI40+
el_BFI41+ el_BFI42+ el_BFI43+ el_BFI44,
data=D, x=T,n.impute=5 , nk=0, type="pmm")
#Creating five data sets with different imputed values
#DImp1 is the data frame reported in the paper.
#The overall prediction of empathy from personality was examined on the other 4 datasets as a robustness check
DImp1_B5 <-as.data.frame(impute.transcan(Imp_B5,imputation=1,data=D,list.out=T,pr=F))
DImp2_B5 <-as.data.frame(impute.transcan(Imp_B5,imputation=2,data=D,list.out=T,pr=F))
DImp3_B5 <-as.data.frame(impute.transcan(Imp_B5,imputation=3,data=D,list.out=T,pr=F))
DImp4_B5 <-as.data.frame(impute.transcan(Imp_B5,imputation=4,data=D,list.out=T,pr=F))
DImp5_B5 <-as.data.frame(impute.transcan(Imp_B5,imputation=5,data=D,list.out=T,pr=F))
col <- colnames(D)
varsEmp <- c(which(col=="EMPQ_emotional"), which(col=="EMPQ_cognitive"))
DImp1 <-cbind.data.frame(D[,c(1,2)],DImp1_B5, D[,varsEmp])
DImp2 <-cbind.data.frame(D[,c(1,2)],DImp2_B5, D[,varsEmp])
DImp3 <-cbind.data.frame(D[,c(1,2)],DImp3_B5, D[,varsEmp])
DImp4 <-cbind.data.frame(D[,c(1,2)],DImp4_B5, D[,varsEmp])
DImp5 <-cbind.data.frame(D[,c(1,2)],DImp5_B5, D[,varsEmp])
#2) reverse items
CreateReverseItems_allData <-function(DImp) {
DImp$el_BFI6_Rev <-  6-DImp$el_BFI6
DImp$el_BFI21_Rev <- 6-DImp$el_BFI21
DImp$el_BFI31_Rev <- 6-DImp$el_BFI31
DImp$el_BFI2_Rev <-  6-DImp$el_BFI2
DImp$el_BFI12_Rev <- 6-DImp$el_BFI12
DImp$el_BFI27_Rev <- 6-DImp$el_BFI27
DImp$el_BFI37_Rev <- 6-DImp$el_BFI37
DImp$el_BFI8_Rev <-  6-DImp$el_BFI8
DImp$el_BFI18_Rev <- 6-DImp$el_BFI18
DImp$el_BFI23_Rev <- 6-DImp$el_BFI23
DImp$el_BFI43_Rev <- 6-DImp$el_BFI43
DImp$el_BFI9_Rev <-  6-DImp$el_BFI9
DImp$el_BFI24_Rev <- 6-DImp$el_BFI24
DImp$el_BFI34_Rev <- 6-DImp$el_BFI34
DImp$el_BFI35_Rev <- 6-DImp$el_BFI35
DImp$el_BFI41_Rev <- 6-DImp$el_BFI41
assign ("DImp",DImp,envir = .GlobalEnv)
}
CreateReverseItems_allData(DImp1)
DImp1.1 <- DImp
#############################################################################################
######################### Ridge regression ##################################################
#############################################################################################
#defining the relevant variables
col <- colnames(DImp1.1)
relvar_emotional <- c(which (col=="EMPQ_emotional"),
which (col=="el_BFI1"), which (col=="el_BFI2_Rev"), which (col=="el_BFI3"),which (col=="el_BFI4"),
which (col=="el_BFI5"),which (col=="el_BFI6_Rev"),which (col=="el_BFI7"),which (col=="el_BFI8_Rev"),
which (col=="el_BFI9_Rev"),which (col=="el_BFI10"),which (col=="el_BFI11"),which (col=="el_BFI12_Rev"),
which (col=="el_BFI13"),which (col=="el_BFI14"),which (col=="el_BFI15"),which (col=="el_BFI16"),
which (col=="el_BFI17"),which (col=="el_BFI18_Rev"),which (col=="el_BFI19"),which (col=="el_BFI20"),
which (col=="el_BFI21_Rev"),which (col=="el_BFI22"),which (col=="el_BFI23_Rev"),which (col=="el_BFI24_Rev"),
which (col=="el_BFI25"),which (col=="el_BFI26"),which (col=="el_BFI27_Rev"),which (col=="el_BFI28"),
which (col=="el_BFI29"),which (col=="el_BFI30"),which (col=="el_BFI31_Rev"),which (col=="el_BFI32"),
which (col=="el_BFI33"),which (col=="el_BFI34_Rev"),which (col=="el_BFI35_Rev"),which (col=="el_BFI36"),
which (col=="el_BFI37_Rev"),which (col=="el_BFI38"),which (col=="el_BFI39"),which (col=="el_BFI40"),
which (col=="el_BFI41_Rev"),which (col=="el_BFI42"),which (col=="el_BFI43_Rev"),which (col=="el_BFI44"))
relvar_cognitive <- c(which(col=="EMPQ_cognitive"),
which (col=="el_BFI1"), which (col=="el_BFI2_Rev"), which (col=="el_BFI3"),which (col=="el_BFI4"),
which (col=="el_BFI5"),which (col=="el_BFI6_Rev"),which (col=="el_BFI7"),which (col=="el_BFI8_Rev"),
which (col=="el_BFI9_Rev"),which (col=="el_BFI10"),which (col=="el_BFI11"),which (col=="el_BFI12_Rev"),
which (col=="el_BFI13"),which (col=="el_BFI14"),which (col=="el_BFI15"),which (col=="el_BFI16"),
which (col=="el_BFI17"),which (col=="el_BFI18_Rev"),which (col=="el_BFI19"),which (col=="el_BFI20"),
which (col=="el_BFI21_Rev"),which (col=="el_BFI22"),which (col=="el_BFI23_Rev"),which (col=="el_BFI24_Rev"),
which (col=="el_BFI25"),which (col=="el_BFI26"),which (col=="el_BFI27_Rev"),which (col=="el_BFI28"),
which (col=="el_BFI29"),which (col=="el_BFI30"),which (col=="el_BFI31_Rev"),which (col=="el_BFI32"),
which (col=="el_BFI33"),which (col=="el_BFI34_Rev"),which (col=="el_BFI35_Rev"),which (col=="el_BFI36"),
which (col=="el_BFI37_Rev"),which (col=="el_BFI38"),which (col=="el_BFI39"),which (col=="el_BFI40"),
which (col=="el_BFI41_Rev"),which (col=="el_BFI42"),which (col=="el_BFI43_Rev"),which (col=="el_BFI44"))
#changing the names of age 11 and age 13 to be the same
newnames <- gsub(x=colnames(DImp1.1[,relvar_emotional]),pattern="el_", replacement="")
colnames(DImp1.1)[relvar_emotional] <- newnames
#dividing the 6 folds so two twins from the same family will always be in the same test fold
#gfold is the variable allocating family to a sepcific fold
unique_ifams <- unique(DImp1.1$ifam)
set.seed(32189)
unique_ifams <- sample(unique_ifams)
remainder<-length(unique_ifams)%%6
nfold <- (length(unique_ifams)-remainder)/6
gfold <- c(rep(1, times=nfold), rep(2, times=nfold), rep(3, times=nfold),
rep(4, times=nfold), rep(5, times=nfold), rep(6, times=nfold))
gfold <- c(gfold,1:remainder)
unique_ifams <- cbind(unique_ifams,gfold)
ifams<- as.data.frame(rbind(unique_ifams, unique_ifams))
colnames(ifams) <- c("ifam","gfold")
ifams$ID<- c(rep(1,times=nrow(unique_ifams)),rep(4,times=nrow(unique_ifams)))  # allocate ID for each twin (ID 1=older twin, ID 4= younger twin)
DImp1.1<- merge(DImp1.1,ifams, by=c("ifam","ID"), all.x = T, all.y = F)        #merge the gfold var with the data
#############################################################################################
######################### Ridge regression ##################################################
#############################################################################################
#create a vector of possible lambda values. These values will be examined in
#a nexted cross-validation procedure to find the optimal lambda that produces the lowest prediction error
# lambdas <- 10^seq(3, -2, by = -.1)
#ridge regression function
Ridge <- function (DImp,gfold,relvar) {
#find the best lambda-
#use glmnet default range search by lambda=NULL
#alpha=0 means we use Ridge regression (as opposed to lasso regression)
#nfolds=10 means that the nested cross-validation proceudre to find the optimal lambda is perdormed on 10 folds
set.seed(10000)
cv_fit <- cv.glmnet(x=as.matrix(DImp[DImp$gfold != gfold,relvar[2:45]]),
y=DImp[DImp$gfold != gfold,relvar[1]],
alpha=0, lambda=NULL,nfolds=10)
opt_lambda <- cv_fit$lambda.min          #find the optimal lambda which produces the lowest prediction error
opt_lambda_ind <- which(cv_fit$lambda==opt_lambda)   #find the optimal lambda index inside the vector
#what are the coefficients when the lambda is optimal?
opt_coef <- as.matrix(cv_fit$glmnet.fit$beta[,opt_lambda_ind])
#after finding the best lambda, train the entire train set with that lambda
fit <- glmnet(x=as.matrix(DImp[DImp$gfold != gfold,relvar[2:45]]),
y=DImp[DImp$gfold != gfold,relvar[1]],
alpha = 0, lambda = opt_lambda)
#now check the prediction on the test set
y_pred <- predict(fit, s=opt_lambda,
newx = as.matrix(DImp[DImp$gfold == gfold,relvar[2:45]]))
mse <- mean((DImp[DImp$gfold == gfold,relvar[1]]-y_pred)^2)     #squared difference between y and y predicted
mean_train <- mean(DImp[DImp$gfold != gfold,relvar[1]])         #mean y (empathy score)
assign ("fit",fit,envir = .GlobalEnv)                           #glmnet ridge regression results
assign ("opt_lambda",opt_lambda,envir = .GlobalEnv)             #optimal lambda value
assign ("opt_coef",opt_coef,envir = .GlobalEnv)                 #items' coefficients when the lambda is optimal
assign ("y_pred",y_pred,envir = .GlobalEnv)                     #y predicted for each participant
assign ("mse", mse,envir = .GlobalEnv)                          #mse for the test set
}
#scale all the BFI items so they all will mean=0 and SD=1
for (i in 2:45) {DImp1.1[,relvar_emotional[i]] <-
scale(DImp1.1[,relvar_emotional[i]], scale=T)}
#doing Ridge regression on the folds - emotional empathy
#fold 1
Ridge(DImp=DImp1.1,gfold=1,relvar=relvar_emotional)
fit_emo11_1 <- fit
opt_lambda_emo11_1 <- opt_lambda
opt_coef_emo11_1 <- opt_coef
y_pred_emo11_1 <- y_pred
mse_emo11_1 <- mse
#fold 2
Ridge(DImp=DImp1.1,gfold=2,relvar=relvar_emotional)
fit_emo11_2 <- fit
opt_lambda_emo11_2 <- opt_lambda
opt_coef_emo11_2 <- opt_coef
y_pred_emo11_2 <- y_pred
mse_emo11_2 <- mse
#fold 3
Ridge(DImp=DImp1.1,gfold=3,relvar=relvar_emotional)
fit_emo11_3 <- fit
opt_lambda_emo11_3 <- opt_lambda
opt_coef_emo11_3 <- opt_coef
y_pred_emo11_3 <- y_pred
mse_emo11_3 <- mse
#fold 4
Ridge(DImp=DImp1.1,gfold=4,relvar=relvar_emotional)
fit_emo11_4 <- fit
opt_lambda_emo11_4 <- opt_lambda
opt_coef_emo11_4 <- opt_coef
y_pred_emo11_4 <- y_pred
mse_emo11_4 <- mse
#fold 5
Ridge(DImp=DImp1.1,gfold=5,relvar=relvar_emotional)
fit_emo11_5 <- fit
opt_lambda_emo11_5 <- opt_lambda
opt_coef_emo11_5 <- opt_coef
y_pred_emo11_5 <- y_pred
mse_emo11_5 <- mse
#fold 6
Ridge(DImp=DImp1.1,gfold=6,relvar=relvar_emotional)
fit_emo11_6 <- fit
opt_lambda_emo11_6 <- opt_lambda
opt_coef_emo11_6 <- opt_coef
y_pred_emo11_6 <- y_pred
mse_emo11_6 <- mse
#computing the mean coefficients across the folds
opt_coef_emo11_matrix <- as.data.frame(cbind (opt_coef_emo11_1,
opt_coef_emo11_2,
opt_coef_emo11_3,
opt_coef_emo11_4,
opt_coef_emo11_5,
opt_coef_emo11_6))
opt_coef_emo11_matrix$aveCoef <- rowMeans(opt_coef_emo11_matrix)
#finding the mean correlation between the outcome and predicted value (y pred) across the folds
cor_emo11 <-1:6
#first do this for each test set
for (i in 1:6) {
cor_emo11[i] <- cor.test(DImp1.1$EMPQ_emotional[DImp1.1$gfold ==i],
eval(parse(text=paste0("y_pred_emo11_",i))))[4]}
cor_emo11 <- as.numeric(cor_emo11)
#now average across all the folds
avecor_emo11 <- mean(cor_emo11)
#computing the mean mse across the folds
mse_emo11 <-1:6
for (i in 1:6) { mse_emo11[i] <- eval(parse(text=paste0("mse_emo11_",i)))}
avemse_emo11 <- mean(mse_emo11)
avecor_emo11
avemse_emo11
#grouping according to the original Big-Five domains
opt_coef_emo11_matrix$category <- NA
#EXTRAVERSION
for (i in c(1,11,16,26,36)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i)] <- "E"}
#reverse items
for (i in c(6,21,31)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i,"_Rev")] <- "E"}
View(opt_coef_emo11_matrix)
#AGREABELNESS
for (i in c(7,17,22,32,42)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i)] <- "A"}
#reverse items
for (i in c(2,12,27,37)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i,"_Rev")] <- "A"}
#OPENESS
for (i in c(5,10,15,20,25,30,40,44)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i)] <- "O"}
#reverse items
for (i in c(35,41)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i,"_Rev")]<- "O"}
#CONCIENCIOUSNESS
for (i in c(3,13,28,33,38)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i)] <- "C"}
#reverse items
for (i in c(8,18,23,43)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i,"_Rev")]<- "C"}
#NEUROTICISM
for (i in c(4,14,19,29,39)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i)] <- "N"}
#reverse items
for (i in c(9,24,34)){
opt_coef_emo11_matrix$category[rownames(opt_coef_emo11_matrix)==paste0("BFI",i,"_Rev")]<-"N"}
BFI_labels <- read.csv ("../OSF/BFI items.csv")
BFI_labels <- read.csv ("../OSF/data/BFI items.csv")
View(BFI_labels)
opt_coef_emo11_matrix$item <- rownames(opt_coef_emo11_matrix)
opt_coef_emo11_matrix <- cbind(opt_coef_emo11_matrix, BFI_labels)
#Packages
packages <- c('psych', 'Hmisc', 'glmnet','ggplot2')
lapply(packages, require, character.only = TRUE)
plotemo11 <- ggplot(data= opt_coef_emo11_matrix,
aes(reorder(x=opt_coef_emo11_matrix$label,opt_coef_emo11_matrix$aveCoef),
y=opt_coef_emo11_matrix$aveCoef,
fill=opt_coef_emo11_matrix$category))+
geom_bar(stat="identity")+ coord_flip()+
ggtitle("Regression coefficients of  personality indicators")+
labs(x="Personality indicator", y="Regression coefficient", fill="Big5 scale")+
scale_fill_manual(values=c("#F8A6F8", "#F7563B", "#F59D3D", "#433FF3", "#5FD3D3"))+
theme_bw()+ theme(legend.position=c(0.95, 0.15), legend.title = element_text(size=12),
plot.title=element_text(size=16, face="bold", family="serif",hjust = 0.5),
axis.title =element_text(size=12, face="bold", family="serif"),
text=element_text(family="serif"))
plotemo11
#doing Ridge regression on the folds- cognitive empathy
#fold 1
Ridge(DImp=DImp1.1,gfold=1,relvar=relvar_cognitive)
fit_cog11_1 <- fit
opt_lambda_cog11_1 <- opt_lambda
opt_coef_cog11_1 <- opt_coef
y_pred_cog11_1 <- y_pred
mse_cog11_1 <- mse
#fold 2
Ridge(DImp=DImp1.1,gfold=2,relvar=relvar_cognitive)
fit_cog11_2 <- fit
opt_lambda_cog11_2 <- opt_lambda
opt_coef_cog11_2 <- opt_coef
y_pred_cog11_2 <- y_pred
mse_cog11_2 <- mse
#fold 3
Ridge(DImp=DImp1.1,gfold=3,relvar=relvar_cognitive)
fit_cog11_3 <- fit
opt_lambda_cog11_3 <- opt_lambda
opt_coef_cog11_3 <- opt_coef
y_pred_cog11_3 <- y_pred
mse_cog11_3 <- mse
#fold 4
Ridge(DImp=DImp1.1,gfold=4,relvar=relvar_cognitive)
fit_cog11_4 <- fit
opt_lambda_cog11_4 <- opt_lambda
opt_coef_cog11_4 <- opt_coef
y_pred_cog11_4 <- y_pred
mse_cog11_4 <- mse
#fold 5
Ridge(DImp=DImp1.1,gfold=5,relvar=relvar_cognitive)
fit_cog11_5 <- fit
opt_lambda_cog11_5 <- opt_lambda
opt_coef_cog11_5 <- opt_coef
y_pred_cog11_5 <- y_pred
mse_cog11_5 <- mse
#fold 6
Ridge(DImp=DImp1.1,gfold=6,relvar=relvar_cognitive)
fit_cog11_6 <- fit
opt_lambda_cog11_6 <- opt_lambda
opt_coef_cog11_6 <- opt_coef
y_pred_cog11_6 <- y_pred
mse_cog11_6 <- mse
#computing the mean coefficients across the folds
opt_coef_cog11_matrix <- as.data.frame(cbind (opt_coef_cog11_1,
opt_coef_cog11_2,
opt_coef_cog11_3,
opt_coef_cog11_4,
opt_coef_cog11_5,
opt_coef_cog11_6))
opt_coef_cog11_matrix$aveCoef <- rowMeans(opt_coef_cog11_matrix)
#finding the mean correlation between outcome and predicted value across the folds
cor_cog11 <-1:6
for (i in 1:6) {
cor_cog11[i] <- cor.test(DImp1.1$EMPQ_cognitive[DImp1.1$gfold ==i],
eval(parse(text=paste0("y_pred_cog11_",i))))[4]}
cor_cog11 <- as.numeric(cor_cog11)
avecor_cog11 <- mean(cor_cog11)
cor_cog11
avecor_cog11
#computing the mean mse across the folds
mse_cog11 <-1:6
for (i in 1:6) { mse_cog11[i] <- eval(parse(text=paste0("mse_cog11_",i)))}
avemse_cog11 <- mean(mse_cog11)
avemse_cog11
colnames(DImp[DImp$gfold != gfold,relvar[1]])
relvar=relvar_emotional
colnames(DImp[DImp$gfold != gfold,relvar[1]])
DImp1.1[,relvar[1]]
View(D)
#Visualize the coefficients graph
#allocate items to their original Big-Five domains
opt_coef_cog11_matrix$category <- NA
#EXTRAVERSION
for (i in c(1,11,16,26,36)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i)] <- "E"}
#reverse items
for (i in c(6,21,31)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i,"_Rev")] <- "E"}
#AGREABELNESS
for (i in c(7,17,22,32,42)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i)] <- "A"}
#reverse items
for (i in c(2,12,27,37)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i,"_Rev")] <- "A"}
#OPENESS
for (i in c(5,10,15,20,25,30,40,44)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i)] <- "O"}
#reverse items
for (i in c(35,41)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i,"_Rev")]<- "O"}
#CONCIENCIOUSNESS
for (i in c(3,13,28,33,38)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i)] <- "C"}
#reverse items
for (i in c(8,18,23,43)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i,"_Rev")]<- "C"}
#NEUROTICISM
for (i in c(4,14,19,29,39)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i)] <- "N"}
#reverse items
for (i in c(9,24,34)){
opt_coef_cog11_matrix$category[rownames(opt_coef_cog11_matrix)==paste0("BFI",i,"_Rev")]<-"N"}
opt_coef_cog11_matrix$item <- rownames(opt_coef_cog11_matrix)
opt_coef_cog11_matrix <- cbind(opt_coef_cog11_matrix, BFI_labels)
plotcog11 <- ggplot(data= opt_coef_cog11_matrix,
aes(reorder(x=opt_coef_cog11_matrix$label,opt_coef_cog11_matrix$aveCoef),
y=opt_coef_cog11_matrix$aveCoef,
fill=opt_coef_cog11_matrix$category))+
geom_bar(stat="identity")+ coord_flip()+
ggtitle("Regression coefficients of  personality indicators")+
labs(x="Personality indicator", y="Regression coefficient", fill="Big5 scale")+
scale_fill_manual(values=c("#F8A6F8", "#F7563B", "#F59D3D", "#433FF3", "#5FD3D3"))+
theme_bw()+ theme(legend.position=c(0.95, 0.15), legend.title = element_text(size=12),
plot.title=element_text(size=16, face="bold", family="serif",hjust = 0.5),
axis.title =element_text(size=12, face="bold", family="serif"),
text=element_text(family="serif"))
plotcog11
